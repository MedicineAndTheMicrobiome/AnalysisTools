#!/usr/bin/env Rscript

###############################################################################

library('getopt');
options(useFancyQuotes=F);
options(width=120);

params=c(
	"taxa_fn", "T", 1, "character",
	"taxa_cn", "t", 1, "character",
	"annot_fn", "A", 1, "character",
	"annot_cn", "a", 1, "character",
	"go_grp_map_fn", "m", 1, "character",
	"output", "o", 1, "character"
);

opt=getopt(spec=matrix(params, ncol=4, byrow=TRUE), debug=FALSE);
script_name=unlist(strsplit(commandArgs(FALSE)[4],"=")[1])[2];

usage = paste(
	"\nUsage:\n", script_name, "\n",
	"	-T <taxa file: read_id to taxa levels>\n",
	"	-t <taxa column name: eg., Species, Genus, ...>\n",
	"	-A <annotation file>\n",
	"	-a <GO ID column name: eg., GOProcIDs, GOFuncIDs, GOCompIDs>\n",
	"	-M <Mapping File: .groupings.map\n",
	"	-o <Output Filename Root>\n",
	"\n",
	"This script will join the taxa and annotation file together and.\n",
	"  generate a 2D matrix.  The rows are the taxa and the columns\n",
	"  are the function.\n",
	"\n",
	"The taxa level must be specified:\n",
	"	Species, Genus, Family, Order, Class, Phylum, Kingdom, Superkingdom\n",
	"\n",
	"The function column needs to be specified:\n",
	"	GOProcIDs, GOFuncIDs, GOCompIDs\n",
	"\n",
	"The mapping file should be generated by the 'find_GO_children'.\n",
	"\n",
	"\n");

if(
	!length(opt$taxa_fn) || 
	!length(opt$taxa_cn) || 
	!length(opt$annot_fn) || 
	!length(opt$annot_cn) || 
	!length(opt$go_grp_map) || 
	!length(opt$output)
){
	cat(usage);
	q(status=-1);
}

TaxaFileName=opt$taxa_fn;
TaxaColumnName=opt$taxa_cn;
AnnotationFileName=opt$annot_fn;
AnnotationColumnName=opt$annot_cn;
GOGrpMapFileName=opt$go_grp_map_fn;
OutputFileNameRoot=opt$output;

cat("Taxa File Name: ", TaxaFileName, "\n");
cat("Taxa Column Name: ", TaxaColumnName, "\n");
cat("Annotation File Name: ", AnnotationFileName, "\n");
cat("Annotation Column Name: ", AnnotationColumnName, "\n");
cat("GO Group Map File Name: ", GOGrpMapFileName, "\n");
cat("Output File Name Root: ", OutputFileNameRoot, "\n");

##############################################################################

load_taxa_file=function(fn, target_level){
# Returns a matrix with 1 column (the targeted taxa level) and a row for each
# read ID.

	cat("Reading: ", fn, "\n");
	cat("Targetting : ", target_level, "\n");

	data=read.delim(fn, comment.char="", header=T);

	read_id=data[,1];
	targeted=data[,target_level, drop=F];
	rownames(targeted)=read_id;
	return(targeted);
}

#------------------------------------------------------------------------------

load_annotation_file=function(fn, annot){
# Returns a matrix with 1 column (the targeted annotation column) and a row for each
# read ID.
	cat("Reading: ", fn, "\n");
	cat("Targetting : ", annot, "\n");

	data=read.delim(fn, comment.char="", header=T);

	read_id=data[,1];
	targeted=data[,annot, drop=F];
	rownames(targeted)=read_id;
	return(targeted);
}

#------------------------------------------------------------------------------

load_gogrpmap_file=function(fn){
# Reads group map	
	cat("Reading: ", fn, "\n");

	data=read.delim(fn, comment.char="", header=T);

	group_ids=data[,"GroupID"];
	member_ids=data[,"Member"];
	lookup=setNames(group_ids, member_ids);

	unique_group_ids=sort(unique(group_ids));
	child_entries=data[member_ids==group_ids,,drop=F];
	child_defin=setNames(child_entries[,"Description"], child_entries[,"Member"]);

	grp_info=list();
	grp_info[["lookup"]]=lookup;	# Map from all descendents to child
	grp_info[["definitions"]]=child_defin;	# Map from child ID to description
	return(grp_info);
}

##############################################################################

remap_annotation_map=function(annot_map, go_map){
# This function will take the annotation tuples, then find the immediate 
# children. If there are multiple annotation IDs, and only some of them
# map were targeted, then the non-targeted will be set to NA.

	num_annotated=nrow(annot_map);
	cat("Num Annotated: ", num_annotated, "\n");

	read_ids=rownames(annot_map);
	annot_ids=annot_map[,1];
	keep_arr=numeric(num_annotated);
	annot_list=list();

	#print(read_ids);
	#print(annot_ids);
	#print(go_map);

	split_list=strsplit(annot_ids, ";");
	#print(split_list);

	# Remap IDs to immediate children
	for(i in 1:num_annotated){
		annot_ids=split_list[[i]];
		num_ids=length(annot_ids);
		recat=go_map$lookup[annot_ids];
		annot_list[[i]]=recat;
	}
	names(annot_list)=read_ids;

	# Remove reads that don't hit any of the targeted annotation IDs
	for(read_id in read_ids){
		rec=annot_list[[read_id]];
		if(length(rec)==0 || all(is.na(rec))){
			annot_list[[read_id]]=NULL;
		}
	}

	return(annot_list);

}

##############################################################################

weighted_tuple_to_2D_matrix=function(wgt_tup_mat){

	unique_taxa=sort(unique(wgt_tup_mat[,"Taxonomy"]));
	unique_annt=sort(unique(wgt_tup_mat[,"Function"]));

	num_unique_taxa=length(unique_taxa);
	num_unique_annt=length(unique_annt);

	cat("Num Unique Taxa: ", num_unique_taxa, "\n");
	cat("Num Unique Annot: ", num_unique_annt, "\n");

	acc_mat=matrix(0, ncol=num_unique_annt, nrow=num_unique_taxa);
	colnames(acc_mat)=unique_annt;
	rownames(acc_mat)=unique_taxa;

	num_tuples=nrow(wgt_tup_mat);

	for(entry_ix in 1:num_tuples){
		tax=wgt_tup_mat[entry_ix,"Taxonomy"];
		ant=wgt_tup_mat[entry_ix,"Function"];
		wgt=wgt_tup_mat[entry_ix,"Weight"];

		acc_mat[tax, ant] = acc_mat[tax, ant] + as.numeric(wgt);
	}

	row_margin=apply(acc_mat, 1, sum);
	col_margin=apply(acc_mat, 2, sum);

	row_decr_order=order(row_margin, decreasing=T);
	col_decr_order=order(col_margin, decreasing=T);

	acc_mat=acc_mat[row_decr_order, col_decr_order, drop=F];

	return(acc_mat);

}

normalize_whole_matrix=function(mat){
	total=sum(mat);
	norm_mat=mat/total;
}

##############################################################################

if(1){
	taxa_read_map=load_taxa_file(fn=TaxaFileName, target_level=TaxaColumnName);
	#print(taxa_read_map);

	annotation_map=load_annotation_file(fn=AnnotationFileName, annot=AnnotationColumnName);
	#print(annotation_map);

	gogrp_map=load_gogrpmap_file(GOGrpMapFileName);
	#print(gogrp_map);
	cat("Targeted Children:\n");
	child_def=gogrp_map[["definitions"]];
}

# 1.) Go through annotation file
# 2.) Find GO IDs that are in GO Grp Map, if found record ReadID in table (read_id, GO, Taxa)
# 3.) Export as Matrix, export as table


remapped_map=remap_annotation_map(annotation_map, gogrp_map);
annotated_read_ids=names(remapped_map);
num_remapped=length(annotated_read_ids);
#print(remapped_map);
#print(annotated_read_ids);
cat("Num Relevant Read IDs: ", num_remapped, "\n");

taxa_wannot=taxa_read_map[annotated_read_ids,];
names(taxa_wannot)=annotated_read_ids;


tuples=list();
idx=1;
for(read_id in annotated_read_ids){
	#cat("Read ID: ", read_id, "\n", sep="");
	#cat("Annotation: \n");
	rmpd=remapped_map[[read_id]];
	#print(rmpd)
	weight=1/length(rmpd);
	nona=rmpd[!is.na(rmpd)];
	#cat("Taxonomy: ", taxa_wannot[read_id], "\n");
	#cat("\n\n");

	for(nona_ix in 1:length(nona)){
		tuples[[idx]]=c(read_id, taxa_wannot[read_id], weight, nona[nona_ix]);
		idx=idx+1;
	}
}

cat("List Length: ", idx-1, "\n");

# Convert tuples to matrix
read_to_annot_taxa_matrix=do.call(rbind, tuples);
colnames(read_to_annot_taxa_matrix)=c("ReadID", "Taxonomy", "Weight", "Function");
#print(read_to_annot_taxa_matrix);

# Sum up all the annotations that were targeted and weighted, into a 2D matrix
# with rows (taxa) x columns (function).
two_d_mat=weighted_tuple_to_2D_matrix(read_to_annot_taxa_matrix);
#print(two_d_mat);

# Normalize the counts, so they all sum up to one.  Presumably and single
# input file is a single sample's compositional counts.
two_d_mat_norm=normalize_whole_matrix(two_d_mat);
#print(two_d_mat_norm);

##############################################################################
# Export various formats after joining the taxa with function

# Tuples Matrix
tuplesfn=paste(OutputFileNameRoot, ".tuples.tsv", sep="");
write.table(read_to_annot_taxa_matrix, file=tuplesfn, quote=F, sep="\t", row.names=F, col.names=T);

# Output Counts
countsmatfn=paste(OutputFileNameRoot, ".cnt_mat.tsv", sep="");
outmat=cbind(rownames(two_d_mat), round(two_d_mat,3));
colnames(outmat)=c("Taxonomy", colnames(two_d_mat));
write.table(outmat, file=countsmatfn, quote=F, sep="\t", row.names=F, col.names=T);

# Output Normalized
normmatfn=paste(OutputFileNameRoot, ".nrm_mat.tsv", sep="");
outmat=cbind(rownames(two_d_mat_norm), round(two_d_mat_norm,8));
colnames(outmat)=c("Taxonomy", colnames(two_d_mat_norm));
write.table(outmat, file=normmatfn, quote=F, sep="\t", row.names=F, col.names=T);

# Output Normalized w clean Descriptions and taxa names
clean_func_name=make.names(child_def[colnames(two_d_mat)]);
clean_taxa_name=make.names(gsub("[\\(\\)]","", rownames(two_d_mat_norm)));

normmatfn=paste(OutputFileNameRoot, ".nrm_mat.cln_desc.tsv", sep="");
outmat=cbind(clean_taxa_name, round(two_d_mat_norm,8));
colnames(outmat)=c("Taxonomy", clean_func_name);
write.table(outmat, file=normmatfn, quote=F, sep="\t", row.names=F, col.names=T);


##############################################################################

cat("\nDone.\n");

print(warnings());
q(status=0);
